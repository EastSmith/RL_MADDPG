{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Collecting paddlepaddle-gpu==1.6.3.post97\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/b9/56/6d47d976831d5b62c1e6aad3d83504bf3fbfd1162c2b3b7733d73c4d0403/paddlepaddle_gpu-1.6.3.post97-cp37-cp37m-manylinux1_x86_64.whl (332.3MB)\n",
      "\u001b[K     |████████████████████████████████| 332.3MB 79kB/s  eta 0:00:016    |██████▎                         | 65.0MB 8.5MB/s eta 0:00:32     |████████                        | 84.0MB 8.8MB/s eta 0:00:29     |████████▎                       | 86.2MB 8.8MB/s eta 0:00:28     |████████▌                       | 88.7MB 8.8MB/s eta 0:00:28     |████████▊                       | 90.8MB 8.8MB/s eta 0:00:28     |█████████▉                      | 101.7MB 6.8MB/s eta 0:00:35     |██████████                      | 102.9MB 6.8MB/s eta 0:00:34\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (2.22.0)\n",
      "Requirement already satisfied: scipy; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (1.3.0)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (3.1)\n",
      "Requirement already satisfied: funcsigs in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (1.0.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (4.1.1.26)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (0.13)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (1.12.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (0.7.2)\n",
      "Requirement already satisfied: objgraph in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (3.4.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (7.1.2)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (2.2.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (4.4.0)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (1.16.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (5.1.2)\n",
      "Requirement already satisfied: nltk; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.6.3.post97) (3.4.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.6.3.post97) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.6.3.post97) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.6.3.post97) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.6.3.post97) (2.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.6.3.post97) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.6.3.post97) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.6.3.post97) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.6.3.post97) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.6.3.post97) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu==1.6.3.post97) (41.4.0)\n",
      "Installing collected packages: paddlepaddle-gpu\n",
      "  Found existing installation: paddlepaddle-gpu 1.6.3.post107\n",
      "    Uninstalling paddlepaddle-gpu-1.6.3.post107:\n",
      "      Successfully uninstalled paddlepaddle-gpu-1.6.3.post107\n",
      "Successfully installed paddlepaddle-gpu-1.6.3.post97\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall -y parl  # 说明：AIStudio预装的parl版本太老，容易跟其他库产生兼容性冲突，建议先卸载\r\n",
    "#!pip uninstall -y pandas scikit-learn # 提示：在AIStudio中卸载这两个库再import parl可避免warning提示，不卸载也不影响parl的使用\r\n",
    "\r\n",
    "!pip install paddlepaddle-gpu==1.6.3.post97  -i https://mirror.baidu.com/pypi/simple          #可选安装paddlepaddle-gpu==1.6.3.post107\r\n",
    "#!pip install parl==1.3.1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddlepaddle-gpu     1.6.3.post107  \n",
      "parl                 1.3.1          \n"
     ]
    }
   ],
   "source": [
    "!pip list | grep paddlepaddle\r\n",
    "!pip list | grep parl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **安装gym==0.10.5版本，再安装multiagent-particle-envs-master环境**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: gym==0.10.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.10.5)\n",
      "Requirement already satisfied: requests>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gym==0.10.5) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gym==0.10.5) (1.16.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gym==0.10.5) (1.12.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gym==0.10.5) (1.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.0->gym==0.10.5) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.0->gym==0.10.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.0->gym==0.10.5) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.0->gym==0.10.5) (3.0.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyglet>=1.2.0->gym==0.10.5) (0.18.0)\n"
     ]
    }
   ],
   "source": [
    "#一定要安装gym==0.10.5版本的gym，否则报错\r\n",
    "!pip install gym==0.10.5  -i https://mirror.baidu.com/pypi/simple  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  multiagent-particle-envs-master.zip\r\n",
      "69ee7f85811c77ee651722bc3c332677b2195da1\r\n",
      "   creating: multiagent-particle-envs-master/\r\n",
      "  inflating: multiagent-particle-envs-master/.gitignore  \r\n",
      "  inflating: multiagent-particle-envs-master/LICENSE.txt  \r\n",
      "  inflating: multiagent-particle-envs-master/README.md  \r\n",
      "   creating: multiagent-particle-envs-master/bin/\r\n",
      " extracting: multiagent-particle-envs-master/bin/__init__.py  \r\n",
      "  inflating: multiagent-particle-envs-master/bin/interactive.py  \r\n",
      "  inflating: multiagent-particle-envs-master/make_env.py  \r\n",
      "   creating: multiagent-particle-envs-master/multiagent/\r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/__init__.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/core.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/environment.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/multi_discrete.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/policy.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/rendering.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenario.py  \r\n",
      "   creating: multiagent-particle-envs-master/multiagent/scenarios/\r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/__init__.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_adversary.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_crypto.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_push.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_reference.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_speaker_listener.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_spread.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_tag.py  \r\n",
      "  inflating: multiagent-particle-envs-master/multiagent/scenarios/simple_world_comm.py  \r\n",
      "  inflating: multiagent-particle-envs-master/setup.py  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip multiagent-particle-envs-master.zip\r\n",
    "#cd multiagent-particle-envs-master   &  pip install -e .      #请到终端操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06-28 11:28:13 MainThread @logger.py:224]\u001b[0m Argv: train.py --env simple_tag\n",
      "/home/aistudio/multiagent-particle-envs-master/multiagent/scenarios/__init__.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:73]\u001b[0m agent num: 4\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:74]\u001b[0m observation_space: [Box(16,), Box(16,), Box(16,), Box(14,)]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:75]\u001b[0m action_space: [Discrete(5), Discrete(5), Discrete(5), Discrete(5)]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:76]\u001b[0m obs_shape_n: [16, 16, 16, 14]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:77]\u001b[0m act_shape_n: [5, 5, 5, 5]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:80]\u001b[0m agent 0 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:81]\u001b[0m agent 0 act_n:5\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:80]\u001b[0m agent 1 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:81]\u001b[0m agent 1 act_n:5\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:80]\u001b[0m agent 2 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:81]\u001b[0m agent 2 act_n:5\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:80]\u001b[0m agent 3 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-28 11:28:14 MainThread @train.py:81]\u001b[0m agent 3 act_n:5\n",
      "\u001b[32m[06-28 11:28:14 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:14 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "W0628 11:28:15.460649   383 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\n",
      "W0628 11:28:15.465879   383 device_context.cc:244] device: 0, cuDNN Version: 7.3.\n",
      "\u001b[32m[06-28 11:28:17 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:17 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:17 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:18 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:18 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:18 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:18 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:19 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:19 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:19 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:28:19 MainThread @train.py:131]\u001b[0m Starting...\n",
      "I0628 11:28:19.635653   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:28:19.635776   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:28:19.636656   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:28:19.637349   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:28:19.637890   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:28:19.645097   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:28:19.645198   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:28:19.645896   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:28:19.646493   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:28:19.647015   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:28:19.651820   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:28:19.651917   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:28:19.652748   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:28:19.653519   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:28:19.654098   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:28:19.659173   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:28:19.659268   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:28:19.660151   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:28:19.660754   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:28:19.661312   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[33m[06-28 11:28:19 MainThread @visualdl.py:34]\u001b[0m \u001b[5m\u001b[33mWRN\u001b[0m [VisualDL] logdir is None, will save VisualDL files to train_log/train\n",
      "View the data using: visualdl --logdir=./train_log/train --host=172.21.27.25\n",
      "\u001b[32m[06-28 11:29:51 MainThread @train.py:156]\u001b[0m Steps: 25000, Episodes: 1000, Mean episode reward: -1.309615660595379, Time: 92.155\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py:143: UserWarning: The input is a CompiledProgram, this is not recommended.\n",
      "  \"The input is a CompiledProgram, this is not recommended.\")\n",
      "I0628 11:29:54.046147   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.046298   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.047114   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.047788   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.048367   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.055011   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.055109   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.055860   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.056454   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.057031   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.063416   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.063519   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.064244   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.064846   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.065399   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.070992   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.071085   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.071792   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.072369   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.072933   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.078438   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.078524   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.079272   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.079813   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.080245   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.093030   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.093127   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.098747   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.102897   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.106063   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-28 11:29:54 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0628 11:29:54.364367   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.364432   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.365092   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.365459   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.365738   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.375749   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.375790   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.381227   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.385121   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.388013   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-28 11:29:54 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0628 11:29:54.647099   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.647159   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.647733   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.648089   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.648365   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.657673   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.657713   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.663214   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.667163   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.670083   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-28 11:29:54 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0628 11:29:54.928088   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.928148   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.928799   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.929163   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.929440   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0628 11:29:54.938841   383 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0628 11:29:54.938884   383 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0628 11:29:54.944337   383 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0628 11:29:54.948211   383 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0628 11:29:54.951035   383 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-28 11:29:55 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-28 11:31:40 MainThread @train.py:156]\u001b[0m Steps: 50000, Episodes: 2000, Mean episode reward: -12.286390242733615, Time: 108.89\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py:143: UserWarning: The input is a CompiledProgram, this is not recommended.\n",
      "  \"The input is a CompiledProgram, this is not recommended.\")\n",
      "\u001b[32m[06-28 11:33:30 MainThread @train.py:156]\u001b[0m Steps: 75000, Episodes: 3000, Mean episode reward: 8.43305735682722, Time: 109.431\n",
      "\u001b[32m[06-28 11:35:19 MainThread @train.py:156]\u001b[0m Steps: 100000, Episodes: 4000, Mean episode reward: 11.36647897109083, Time: 109.514\n",
      "\u001b[32m[06-28 11:37:09 MainThread @train.py:156]\u001b[0m Steps: 125000, Episodes: 5000, Mean episode reward: 14.336180532181476, Time: 109.521\n",
      "\u001b[32m[06-28 11:38:58 MainThread @train.py:156]\u001b[0m Steps: 150000, Episodes: 6000, Mean episode reward: 26.7255444083337, Time: 109.72\n",
      "\u001b[32m[06-28 11:40:49 MainThread @train.py:156]\u001b[0m Steps: 175000, Episodes: 7000, Mean episode reward: 52.296378736269205, Time: 110.415\n",
      "\u001b[32m[06-28 11:42:43 MainThread @train.py:156]\u001b[0m Steps: 200000, Episodes: 8000, Mean episode reward: 92.98322737237925, Time: 114.018\n",
      "\u001b[32m[06-28 11:44:35 MainThread @train.py:156]\u001b[0m Steps: 225000, Episodes: 9000, Mean episode reward: 79.66313149746571, Time: 112.071\n",
      "\u001b[32m[06-28 11:46:25 MainThread @train.py:156]\u001b[0m Steps: 250000, Episodes: 10000, Mean episode reward: 51.69763546045388, Time: 110.203\n",
      "\u001b[32m[06-28 11:48:15 MainThread @train.py:156]\u001b[0m Steps: 275000, Episodes: 11000, Mean episode reward: 34.475284823705984, Time: 110.371\n",
      "\u001b[32m[06-28 11:50:05 MainThread @train.py:156]\u001b[0m Steps: 300000, Episodes: 12000, Mean episode reward: 41.982389163536396, Time: 109.721\n",
      "\u001b[32m[06-28 11:51:55 MainThread @train.py:156]\u001b[0m Steps: 325000, Episodes: 13000, Mean episode reward: 48.81720131036671, Time: 109.81\n",
      "\u001b[32m[06-28 11:53:45 MainThread @train.py:156]\u001b[0m Steps: 350000, Episodes: 14000, Mean episode reward: 58.187395852233344, Time: 109.796\n",
      "\u001b[32m[06-28 11:55:34 MainThread @train.py:156]\u001b[0m Steps: 375000, Episodes: 15000, Mean episode reward: 57.01609893331441, Time: 109.448\n",
      "\u001b[32m[06-28 11:57:24 MainThread @train.py:156]\u001b[0m Steps: 400000, Episodes: 16000, Mean episode reward: 52.57503761040454, Time: 109.9\n",
      "\u001b[32m[06-28 11:59:15 MainThread @train.py:156]\u001b[0m Steps: 425000, Episodes: 17000, Mean episode reward: 47.87129751232297, Time: 110.721\n",
      "\u001b[32m[06-28 12:01:05 MainThread @train.py:156]\u001b[0m Steps: 450000, Episodes: 18000, Mean episode reward: 38.74752765935038, Time: 110.191\n",
      "\u001b[32m[06-28 12:02:56 MainThread @train.py:156]\u001b[0m Steps: 475000, Episodes: 19000, Mean episode reward: 26.853039042146435, Time: 111.231\n",
      "\u001b[32m[06-28 12:04:47 MainThread @train.py:156]\u001b[0m Steps: 500000, Episodes: 20000, Mean episode reward: 26.754589354629026, Time: 110.567\n",
      "\u001b[32m[06-28 12:06:38 MainThread @train.py:156]\u001b[0m Steps: 525000, Episodes: 21000, Mean episode reward: 29.80932620352735, Time: 111.026\n",
      "\u001b[32m[06-28 12:08:28 MainThread @train.py:156]\u001b[0m Steps: 550000, Episodes: 22000, Mean episode reward: 30.207694416021596, Time: 110.425\n",
      "\u001b[32m[06-28 12:10:20 MainThread @train.py:156]\u001b[0m Steps: 575000, Episodes: 23000, Mean episode reward: 28.71230682111246, Time: 111.595\n",
      "\u001b[32m[06-28 12:12:10 MainThread @train.py:156]\u001b[0m Steps: 600000, Episodes: 24000, Mean episode reward: 26.84124533289219, Time: 110.612\n",
      "\u001b[32m[06-28 12:14:01 MainThread @train.py:156]\u001b[0m Steps: 625000, Episodes: 25000, Mean episode reward: 24.753203556771403, Time: 110.179\n"
     ]
    }
   ],
   "source": [
    "#!python  train.py \r\n",
    "!python train.py --env simple_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06-30 08:59:42 MainThread @logger.py:224]\u001b[0m Argv: train.py --env simple_world_comm --max_episodes 36000\n",
      "/home/aistudio/multiagent-particle-envs-master/multiagent/scenarios/__init__.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:73]\u001b[0m agent num: 6\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:74]\u001b[0m observation_space: [Box(34,), Box(34,), Box(34,), Box(34,), Box(28,), Box(28,)]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:75]\u001b[0m action_space: [MultiDiscrete2, Discrete(5), Discrete(5), Discrete(5), Discrete(5), Discrete(5)]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:76]\u001b[0m obs_shape_n: [34, 34, 34, 34, 28, 28]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:77]\u001b[0m act_shape_n: [9, 5, 5, 5, 5, 5]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 0 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 0 act_n:9\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:85]\u001b[0m agent 0 act_low:[0 0] act_high:[4 3] act_shape:2\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:87]\u001b[0m num_discrete_space:2\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 1 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 1 act_n:5\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 2 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 2 act_n:5\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 3 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 3 act_n:5\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 4 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 4 act_n:5\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:80]\u001b[0m agent 5 obs_low:[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf] obs_high:[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf]\n",
      "\u001b[32m[06-30 08:59:42 MainThread @train.py:81]\u001b[0m agent 5 act_n:5\n",
      "\u001b[32m[06-30 08:59:42 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:42 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "W0630 08:59:43.937172 19242 device_context.cc:236] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\n",
      "W0630 08:59:43.942454 19242 device_context.cc:244] device: 0, cuDNN Version: 7.3.\n",
      "\u001b[32m[06-30 08:59:45 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:46 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:46 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:46 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:46 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:47 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:47 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:47 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:48 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:48 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:48 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:48 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:49 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:49 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:49 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:50 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 08:59:50 MainThread @train.py:131]\u001b[0m Starting...\n",
      "I0630 08:59:50.135578 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.135713 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.136894 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.138114 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.138994 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 08:59:50.148823 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.148960 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.149797 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.150418 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.150990 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 08:59:50.156505 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.156610 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.157438 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.158051 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.158605 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 08:59:50.164065 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.164167 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.164988 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.165585 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.166153 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 08:59:50.171905 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.172020 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.172814 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.173419 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.173954 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 08:59:50.179386 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 08:59:50.179487 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 08:59:50.180312 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 08:59:50.180904 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 08:59:50.181479 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[33m[06-30 08:59:50 MainThread @visualdl.py:34]\u001b[0m \u001b[5m\u001b[33mWRN\u001b[0m [VisualDL] logdir is None, will save VisualDL files to train_log/train\n",
      "View the data using: visualdl --logdir=./train_log/train --host=172.21.27.25\n",
      "\u001b[32m[06-30 09:03:02 MainThread @train.py:156]\u001b[0m Steps: 25000, Episodes: 1000, Mean episode reward: -22.432156764049857, Time: 192.029\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py:143: UserWarning: The input is a CompiledProgram, this is not recommended.\n",
      "  \"The input is a CompiledProgram, this is not recommended.\")\n",
      "I0630 09:03:06.939173 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.939251 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.940160 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.940785 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.941380 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.948063 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.948117 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.948760 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.949169 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.949540 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.955317 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.955363 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.956010 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.956467 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.956871 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.962926 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.962968 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.963593 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.964007 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.964380 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.969671 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.969709 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.970307 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.970731 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.971099 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.977108 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.977150 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.977775 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.978166 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.978518 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.983844 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.983884 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:06.984442 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:06.984802 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:06.985090 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:06.995383 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:06.995438 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:07.001866 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:07.006472 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:07.009974 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:07 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0630 09:03:07.319620 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:07.319707 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:07.320307 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:07.320701 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:07.320987 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:07.331982 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:07.332042 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:07.337972 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:07.342151 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:07.345086 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:07 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0630 09:03:07.658541 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:07.658645 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:07.659206 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:07.659584 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:07.659885 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:07.671134 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:07.671209 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:07.677088 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:07.681247 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:07.684273 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:07 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0630 09:03:08.001729 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.001940 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.002795 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.003407 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.003908 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:08.016448 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.016607 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.022439 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.026837 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.030021 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:08 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0630 09:03:08.357969 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.358145 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.359091 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.359705 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.360177 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:08.372678 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.372846 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.378852 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.383368 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.386662 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:08 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "I0630 09:03:08.712566 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.712744 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.713562 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.714157 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.714655 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "I0630 09:03:08.726418 19242 parallel_executor.cc:409] If you set build_strategy.reduce with 'Reduce',the number of places should be greater than 1.\n",
      "I0630 09:03:08.726552 19242 parallel_executor.cc:421] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
      "I0630 09:03:08.732529 19242 build_strategy.cc:363] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0630 09:03:08.736963 19242 parallel_executor.cc:285] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0630 09:03:08.740293 19242 parallel_executor.cc:368] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "\u001b[32m[06-30 09:03:09 MainThread @machine_info.py:86]\u001b[0m nvidia-smi -L found gpu count: 1\n",
      "\u001b[32m[06-30 09:06:48 MainThread @train.py:156]\u001b[0m Steps: 50000, Episodes: 2000, Mean episode reward: -47.3986067701633, Time: 226.105\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/io.py:143: UserWarning: The input is a CompiledProgram, this is not recommended.\n",
      "  \"The input is a CompiledProgram, this is not recommended.\")\n",
      "\u001b[32m[06-30 09:10:32 MainThread @train.py:156]\u001b[0m Steps: 75000, Episodes: 3000, Mean episode reward: 8.519961488356792, Time: 224.249\n",
      "\u001b[32m[06-30 09:14:15 MainThread @train.py:156]\u001b[0m Steps: 100000, Episodes: 4000, Mean episode reward: 14.368096977603908, Time: 222.743\n",
      "\u001b[32m[06-30 09:17:56 MainThread @train.py:156]\u001b[0m Steps: 125000, Episodes: 5000, Mean episode reward: 22.318975201750078, Time: 221.057\n",
      "\u001b[32m[06-30 09:21:46 MainThread @train.py:156]\u001b[0m Steps: 150000, Episodes: 6000, Mean episode reward: 26.40225924885014, Time: 229.776\n",
      "\u001b[32m[06-30 09:25:47 MainThread @train.py:156]\u001b[0m Steps: 175000, Episodes: 7000, Mean episode reward: 37.024245986733455, Time: 240.967\n",
      "\u001b[32m[06-30 09:29:41 MainThread @train.py:156]\u001b[0m Steps: 200000, Episodes: 8000, Mean episode reward: 54.41239540936235, Time: 234.666\n",
      "\u001b[32m[06-30 09:33:44 MainThread @train.py:156]\u001b[0m Steps: 225000, Episodes: 9000, Mean episode reward: 49.69225121559298, Time: 242.317\n",
      "\u001b[32m[06-30 09:37:49 MainThread @train.py:156]\u001b[0m Steps: 250000, Episodes: 10000, Mean episode reward: 37.78686677345487, Time: 244.959\n",
      "\u001b[32m[06-30 09:41:59 MainThread @train.py:156]\u001b[0m Steps: 275000, Episodes: 11000, Mean episode reward: 23.23812584102374, Time: 250.887\n",
      "\u001b[32m[06-30 09:46:06 MainThread @train.py:156]\u001b[0m Steps: 300000, Episodes: 12000, Mean episode reward: 15.689984687445174, Time: 246.224\n",
      "\u001b[32m[06-30 09:50:13 MainThread @train.py:156]\u001b[0m Steps: 325000, Episodes: 13000, Mean episode reward: 16.726958197713852, Time: 247.732\n",
      "\u001b[32m[06-30 09:54:24 MainThread @train.py:156]\u001b[0m Steps: 350000, Episodes: 14000, Mean episode reward: 20.740964666942475, Time: 250.937\n",
      "\u001b[32m[06-30 09:58:30 MainThread @train.py:156]\u001b[0m Steps: 375000, Episodes: 15000, Mean episode reward: 18.30211831123031, Time: 245.834\n",
      "\u001b[32m[06-30 10:02:43 MainThread @train.py:156]\u001b[0m Steps: 400000, Episodes: 16000, Mean episode reward: 22.514348840747267, Time: 252.487\n",
      "\u001b[32m[06-30 10:06:49 MainThread @train.py:156]\u001b[0m Steps: 425000, Episodes: 17000, Mean episode reward: 22.7857609295124, Time: 246.413\n",
      "\u001b[32m[06-30 10:11:00 MainThread @train.py:156]\u001b[0m Steps: 450000, Episodes: 18000, Mean episode reward: 24.807938896808533, Time: 250.89\n",
      "\u001b[32m[06-30 10:15:10 MainThread @train.py:156]\u001b[0m Steps: 475000, Episodes: 19000, Mean episode reward: 25.863926894275668, Time: 249.595\n",
      "\u001b[32m[06-30 10:19:54 MainThread @train.py:156]\u001b[0m Steps: 500000, Episodes: 20000, Mean episode reward: 29.052729745259455, Time: 284.609\n",
      "\u001b[32m[06-30 10:24:34 MainThread @train.py:156]\u001b[0m Steps: 525000, Episodes: 21000, Mean episode reward: 33.67119958914772, Time: 279.863\n",
      "\u001b[32m[06-30 10:28:40 MainThread @train.py:156]\u001b[0m Steps: 550000, Episodes: 22000, Mean episode reward: 40.69607378265944, Time: 246.013\n",
      "\u001b[32m[06-30 10:32:47 MainThread @train.py:156]\u001b[0m Steps: 575000, Episodes: 23000, Mean episode reward: 42.8955306785431, Time: 246.544\n",
      "\u001b[32m[06-30 10:36:57 MainThread @train.py:156]\u001b[0m Steps: 600000, Episodes: 24000, Mean episode reward: 46.51414700615195, Time: 250.077\n",
      "\u001b[32m[06-30 10:41:04 MainThread @train.py:156]\u001b[0m Steps: 625000, Episodes: 25000, Mean episode reward: 45.17574387559365, Time: 247.757\n",
      "\u001b[32m[06-30 10:44:57 MainThread @train.py:156]\u001b[0m Steps: 650000, Episodes: 26000, Mean episode reward: 42.13110340289071, Time: 232.54\n",
      "\u001b[32m[06-30 10:48:57 MainThread @train.py:156]\u001b[0m Steps: 675000, Episodes: 27000, Mean episode reward: 45.54828942507619, Time: 239.753\n",
      "\u001b[32m[06-30 10:53:02 MainThread @train.py:156]\u001b[0m Steps: 700000, Episodes: 28000, Mean episode reward: 47.671439892307966, Time: 245.694\n",
      "\u001b[32m[06-30 10:57:18 MainThread @train.py:156]\u001b[0m Steps: 725000, Episodes: 29000, Mean episode reward: 53.63122196457577, Time: 255.141\n",
      "\u001b[32m[06-30 11:01:34 MainThread @train.py:156]\u001b[0m Steps: 750000, Episodes: 30000, Mean episode reward: 51.06072324305278, Time: 256.457\n",
      "\u001b[32m[06-30 11:05:37 MainThread @train.py:156]\u001b[0m Steps: 775000, Episodes: 31000, Mean episode reward: 51.58805669367054, Time: 242.916\n",
      "\u001b[32m[06-30 11:09:41 MainThread @train.py:156]\u001b[0m Steps: 800000, Episodes: 32000, Mean episode reward: 51.269091734827136, Time: 244.296\n",
      "\u001b[32m[06-30 11:13:47 MainThread @train.py:156]\u001b[0m Steps: 825000, Episodes: 33000, Mean episode reward: 59.1188468310133, Time: 245.421\n",
      "\u001b[32m[06-30 11:17:54 MainThread @train.py:156]\u001b[0m Steps: 850000, Episodes: 34000, Mean episode reward: 62.82307518887683, Time: 247.241\n",
      "\u001b[32m[06-30 11:22:02 MainThread @train.py:156]\u001b[0m Steps: 875000, Episodes: 35000, Mean episode reward: 65.74100500567013, Time: 247.895\n",
      "\u001b[32m[06-30 11:26:08 MainThread @train.py:156]\u001b[0m Steps: 900000, Episodes: 36000, Mean episode reward: 62.094690425564224, Time: 246.765\n"
     ]
    }
   ],
   "source": [
    "# #!python simple_model.py\r\n",
    "# #!python  simple_model.py\r\n",
    "#!python  train.py  --env  simple_tag  --max_episodes 50000   simple_world_comm\r\n",
    "!python  train.py  --env  simple_world_comm  --max_episodes 36000   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
